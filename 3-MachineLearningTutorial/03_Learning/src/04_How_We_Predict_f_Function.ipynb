{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1d8bd3",
   "metadata": {},
   "source": [
    "# $f()$ Fonksiyonunu Nasıl Tahmin Ederiz?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca552d7",
   "metadata": {},
   "source": [
    "Dersimiz boyunca, f'yi bulmak için birçok yöntem deneyeceğiz. Lineer Yöntemler, Non-Lineer Yöntemler, Clustering Yöntemleri deneyeceğimiz yöntemlere örnek olarak verilebilir. Bu yöntemler farklı olsalar da, hepsinde aşağıda belirtilen ortak varsayımlarımız olacak:\n",
    "\n",
    "* Her zaman n'in toplam gözlem sayısı (bağımsız veri sayısı) olduğunu kabul edeceğiz.\n",
    "* Bu gözlemlere *'training data'* yani *'eğitme verisi'* diyeceğiz.\n",
    "* Bu training data'yı kullanarak veri içindeki ilişkileri öğreneceğiz.\n",
    "* $X_{ij}$ -> i. satır, j. sütun yani i numaralı gözlemin j numaralı değişkeni,özniteliği\n",
    "   * i = 1, 2, 3,..., n\n",
    "   * j = 1, 2, 3..., p\n",
    "* $y_i$ -> i. gözlemin sonucu yani output/label değişkeni\n",
    "* Amacımız training data üzerinde algoritmalar çalıştırıp bilmediğimiz f'yi tahminlemek\n",
    "* Bu arama işlemi iki temel yapıya ayrılır:\n",
    "    * Parametrik Metodlar\n",
    "    * Non-Parametrik Metodlar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f59004",
   "metadata": {},
   "source": [
    "***\n",
    "## $Parametrik$ $Metodlar$\n",
    "\n",
    "İki adımlı bir yaklaşımdır. Bu adımlar aşağıdaki gibidir:"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1- Önce f() fonksiyonunun şekli üzerine bir varsayımda bulunuruz (BIAS).**\n",
    "\n",
    "Örneğin dağınık bir verimiz olduğunu ve bu veriyi parametre olarak gönderdiğimiz f fonksiyonunun *Lineer* olduğunu varsayabiliriz.\n",
    "\n",
    "$$f(X) = \\beta_o + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p $$\n",
    "\n",
    "Bu bir *Lineer Model* dir. Bu şekilde bir varsayımla artık f'yi tahminlemek için sadece $\\beta$ ları bulmak yeterlidir. Yani $p + 1$ adet $\\beta_0, \\beta_1, ... \\beta_p$ değişkenini. Dikkat ediniz, burada değişkenimiz X değildir, $\\beta$ 'lardır. Çünkü X'ler zaten her gözlem (satır) içinde verilmiştir. Y'yi de bilmekteyiz yani sonucu. Bilmediğimiz tek şey $\\beta$ 'lardır."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src='../images/simple_linear_regression_model.png' />"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "cc06036e",
   "metadata": {},
   "source": [
    "**2- Modeli seçtikten sonra training data üzerinden $\\beta$ 'ları bulacak bir prosedüre (algoritmaya) ihtiyaç duyarız.**\n",
    "\n",
    "Buna train dataya oturacak (fit edecek) bir model bulmak diyoruz. Modelimizin elimizdeki train datasına uyması için $\\beta$ katsayılarımız ne olacak?  İşte bunu verecek bir prosedür gerekiyor bize. Bunun için kursumuz boyunca çeşitli yöntemler göreceğiz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db41e41",
   "metadata": {},
   "source": [
    "***\n",
    "## $Underfitting$ $\\&$ $Overfitting$\n",
    "\n",
    "Gördüğünüz gibi Parametrik Metodlar f'yi bulma meselesini aslında bir parametre tahmini meselesine indirgemiş olur. Dolayısı ile işimiz görece kolaylaşır. Ama bu durumda ortaya başka bir sorun çıkar. O da seçtiğimiz model'in geçekte var olan ama bizim bilmediğimiz modele ne kadar yakınsadığıdır.  Eğer çok alakasız bir model seçimi yaptıysak o zaman bulduğumuz sonuçlar gerçekten uzak olacaktır.\n",
    "\n",
    "**Underfitting:** Başka bir deyişle seçtiğimiz model, gerçek hayattaki kompleksiteyi karşılayamamış demektir. Modelimiz çok basit kalmıştır. Bu soruna Makine Öğrenmesinde `Underfitting` denir. Lineer Modeller genelde basit oldukları için Underfitting'e düşme olasılığı yüksektir.\n",
    "\n",
    "**Overfitting:** Bir başka sorun da seçtiğimiz modelin çok fazla karmaşık olmasında çıkar. Eğer modelimiz gerçek hayattaki gizli fonksiyondan daha karmaşıksa o zaman da `Overfitting` var demektir. Yani modelimiz, veriyi çok fazla yakından izlemiş, yani ezberlemiştir. Eldeki veriyi çok iyi temsil etse de genelleşemez.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c44a2",
   "metadata": {},
   "source": [
    "<img src='../images/overfitting_underfitting.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dacb91",
   "metadata": {},
   "source": [
    "***\n",
    "## $Non$$-$$Parametrik$ $Metodlar$**\n",
    "\n",
    "Parametrik Metodların aksine, Non-Parametrik Metodlar f'in şekli yani model üzerinde bir tahmin yapmazlar.Bunun yerine, direkt olarak veri üzerinden girdi-çıktı (input-output) arasındaki ilişkiyi anlamaya ve f'yi bu şekilde tahminlemeye çalışırlar. Dolayısı ile yanlış bir başlangıç yapma riski ortadan kalkar. Fakat Non-Parametrik Metodların da başka bir sorunu vardır. Çok ama çok veriye ihtiyaç duyarlar. Parametrik metodlarda olduğu gibi Non-Parametrik metodlar aradaki ilişkinin şeklini sabitlemedikleri için tüm olasılıklar masadadır ve bu olasılıkları elemek için büyük miktarda veriye ihtiyaç duyarlar. Ki bu da maliyet demektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03516a4",
   "metadata": {},
   "source": [
    "**Parametrik vs. Non-Parametrik**\n",
    "\n",
    "Gördüğünüz gibi iki metodun da kendisine göre artıları ve eksileri var. Hangisini hangi durumda kullanacağımızı göreceğiz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
