{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "770d1648",
   "metadata": {},
   "source": [
    "## GRADIENT DESCENT (GRADYAN İNİŞİ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112963cf",
   "metadata": {},
   "source": [
    "`Gradient Descent` yöntemi, birbirinden farklı problemler için optimum sonucu bulabilme yeteneğine sahip bir **eniyileme/optimizasyon** algoritmasıdır. Gradient Descent yöntemindeki anafikir, *parametreleri her iterasyonda tekrar revize ederek/ayarlayarak maliyet fonksiyonunu en aza indirmektir.*\n",
    "\n",
    "Bununla birlite Gradient Descent yöntemi, neredeysa bütün Machine Learning algoritmaları için kullanılır ve bu algoritmaların çalışma mantığını içselleştirmek bakımından oldukça mühimdir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2806f137",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1baebea",
   "metadata": {},
   "source": [
    "### DATA OLUŞTURALIM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4c2877",
   "metadata": {},
   "source": [
    "* Gradient Descent yöntemini incelemek üzere kendi örnek verimizi yaratalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7664a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri import edelim.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2cfce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random modülünü kullanarak 100 adet random değişken üretiyoruz ve bu değişkenleri 2 ile çarpıyoruz.\n",
    "# Böylece 0 - 2 aralığında 100 adet değer üretmiş oluyoruz.\n",
    "\n",
    "X = 2 * np.random.rand(100 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "180173b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.56956808e+00]\n",
      " [9.40733761e-01]\n",
      " [1.68717416e+00]\n",
      " [8.37389058e-01]\n",
      " [1.52676037e+00]\n",
      " [1.18035521e+00]\n",
      " [1.43886142e+00]\n",
      " [1.83410254e+00]\n",
      " [1.74732857e-01]\n",
      " [2.72177350e-01]\n",
      " [1.73982845e+00]\n",
      " [2.06980647e-01]\n",
      " [1.56789608e+00]\n",
      " [1.71150730e+00]\n",
      " [6.43144840e-01]\n",
      " [2.94890528e-01]\n",
      " [1.65502279e+00]\n",
      " [1.45691504e+00]\n",
      " [1.35221458e+00]\n",
      " [1.06974283e+00]\n",
      " [9.35405239e-01]\n",
      " [2.14693848e-01]\n",
      " [1.84076673e+00]\n",
      " [2.79235832e-01]\n",
      " [1.94401306e+00]\n",
      " [1.51813875e+00]\n",
      " [7.15001325e-01]\n",
      " [1.48879908e+00]\n",
      " [1.31039102e+00]\n",
      " [1.40366202e+00]\n",
      " [1.98019763e+00]\n",
      " [1.27786757e+00]\n",
      " [1.77999837e+00]\n",
      " [1.56248102e+00]\n",
      " [1.60871987e+00]\n",
      " [1.20263732e+00]\n",
      " [1.95472339e+00]\n",
      " [1.72276752e+00]\n",
      " [7.05695458e-01]\n",
      " [1.49561424e+00]\n",
      " [1.72784840e+00]\n",
      " [2.84579414e-01]\n",
      " [8.17720357e-01]\n",
      " [6.89869613e-01]\n",
      " [1.09615176e+00]\n",
      " [1.94369250e-02]\n",
      " [4.98722947e-01]\n",
      " [1.86953164e+00]\n",
      " [9.95776871e-01]\n",
      " [1.36244968e-01]\n",
      " [6.18254118e-01]\n",
      " [1.32470279e+00]\n",
      " [2.42193286e-02]\n",
      " [1.61182195e+00]\n",
      " [7.21362010e-01]\n",
      " [1.19582806e+00]\n",
      " [9.08283678e-01]\n",
      " [1.61504225e+00]\n",
      " [1.32682768e+00]\n",
      " [1.15167508e+00]\n",
      " [1.09537846e+00]\n",
      " [8.96581950e-01]\n",
      " [5.75118794e-01]\n",
      " [1.36847296e+00]\n",
      " [6.35280046e-01]\n",
      " [1.94482813e+00]\n",
      " [6.30786240e-01]\n",
      " [1.55936063e+00]\n",
      " [5.53390980e-01]\n",
      " [1.77137709e+00]\n",
      " [5.98007304e-01]\n",
      " [1.66797116e+00]\n",
      " [1.19293158e+00]\n",
      " [9.53124868e-01]\n",
      " [6.14883639e-01]\n",
      " [2.92775206e-01]\n",
      " [1.10057480e+00]\n",
      " [2.64300089e-01]\n",
      " [1.73689647e+00]\n",
      " [1.19615848e+00]\n",
      " [1.40712819e+00]\n",
      " [1.34314289e+00]\n",
      " [1.31459454e+00]\n",
      " [6.94780162e-02]\n",
      " [1.64430450e+00]\n",
      " [1.45065767e+00]\n",
      " [6.39565886e-01]\n",
      " [7.30226506e-01]\n",
      " [8.87797538e-01]\n",
      " [1.31597499e+00]\n",
      " [1.58689991e+00]\n",
      " [2.93794327e-01]\n",
      " [6.66514717e-01]\n",
      " [1.15256968e+00]\n",
      " [9.39266768e-01]\n",
      " [7.89563467e-01]\n",
      " [1.36990302e+00]\n",
      " [2.46200953e-01]\n",
      " [1.41984926e+00]\n",
      " [1.33407995e-03]]\n"
     ]
    }
   ],
   "source": [
    "# Ürettiğimiz değerleri görelim.\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1301b849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ürettiğimiz değer listesinin veri tipini öğrenelim.\n",
    "\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7583f1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c856f",
   "metadata": {},
   "source": [
    "**Normalde X ile y arasındaki ilişkiyi önceden bilemeyiz. Bunu, önceki konularda X ile y arasındaki ilişkiyi bulmak için Regresyon modelleri kullanırken öğrenmiştik. Ancak, şu anki senaryoya göre X ile y değerleri arasındaki ilişkiyi bildiğimizi farz ederek işlemlerimizi gerçekleştireceğiz.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cdee5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c46eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X ile y değerleri arasındaki, önceden bilgisine sahip olduğumuzu varsaydığımız, ilişki.\n",
    "\n",
    "# 4 : intercept\n",
    "# 3 : coefficient of X\n",
    "# np.random.rand(100, 1) : Error Term\n",
    "\n",
    "y = 4 + 3 * X + np.random.rand(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c066c8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.77248408]\n",
      " [ 7.46199248]\n",
      " [ 9.97407832]\n",
      " [ 7.43754951]\n",
      " [ 8.66540705]\n",
      " [ 8.02800979]\n",
      " [ 8.75472146]\n",
      " [10.06348536]\n",
      " [ 5.3088695 ]\n",
      " [ 5.47605999]\n",
      " [ 9.45733355]\n",
      " [ 5.51916456]\n",
      " [ 9.45275296]\n",
      " [ 9.45988539]\n",
      " [ 6.4747393 ]\n",
      " [ 4.96174457]\n",
      " [ 9.2968593 ]\n",
      " [ 8.86038361]\n",
      " [ 8.87158313]\n",
      " [ 8.02871358]\n",
      " [ 7.11180692]\n",
      " [ 5.38288843]\n",
      " [ 9.65998949]\n",
      " [ 4.92999948]\n",
      " [10.81381454]\n",
      " [ 9.36075145]\n",
      " [ 6.99888113]\n",
      " [ 9.25020759]\n",
      " [ 8.02277208]\n",
      " [ 8.25161313]\n",
      " [10.52510111]\n",
      " [ 8.22584731]\n",
      " [10.31047521]\n",
      " [ 9.32382907]\n",
      " [ 9.54621194]\n",
      " [ 8.07786641]\n",
      " [10.61264091]\n",
      " [ 9.691152  ]\n",
      " [ 6.44864886]\n",
      " [ 9.06975808]\n",
      " [ 9.94622146]\n",
      " [ 4.86058855]\n",
      " [ 7.07165932]\n",
      " [ 7.06256201]\n",
      " [ 8.25690562]\n",
      " [ 4.61056294]\n",
      " [ 5.60403603]\n",
      " [ 9.80032697]\n",
      " [ 7.57973073]\n",
      " [ 4.85555168]\n",
      " [ 6.7949089 ]\n",
      " [ 8.60496997]\n",
      " [ 4.81204777]\n",
      " [ 8.8864763 ]\n",
      " [ 7.15177892]\n",
      " [ 7.96952399]\n",
      " [ 7.63726935]\n",
      " [ 9.02202818]\n",
      " [ 8.81131554]\n",
      " [ 8.16942505]\n",
      " [ 7.6481214 ]\n",
      " [ 6.8517322 ]\n",
      " [ 6.514575  ]\n",
      " [ 8.54467214]\n",
      " [ 6.5993056 ]\n",
      " [10.5323642 ]\n",
      " [ 6.84933551]\n",
      " [ 9.32906331]\n",
      " [ 5.84857305]\n",
      " [10.05414338]\n",
      " [ 6.13265074]\n",
      " [ 9.30033179]\n",
      " [ 8.4424508 ]\n",
      " [ 7.50722296]\n",
      " [ 6.75857882]\n",
      " [ 5.72122014]\n",
      " [ 7.79170653]\n",
      " [ 5.75060628]\n",
      " [ 9.5374264 ]\n",
      " [ 8.56326784]\n",
      " [ 9.15886356]\n",
      " [ 8.2461172 ]\n",
      " [ 8.17750888]\n",
      " [ 5.04424007]\n",
      " [ 9.25852718]\n",
      " [ 9.32364782]\n",
      " [ 6.1106426 ]\n",
      " [ 6.76239466]\n",
      " [ 6.88997291]\n",
      " [ 8.08942929]\n",
      " [ 8.90522132]\n",
      " [ 4.89671038]\n",
      " [ 6.32859855]\n",
      " [ 8.29510108]\n",
      " [ 7.36831796]\n",
      " [ 6.5827123 ]\n",
      " [ 8.22057273]\n",
      " [ 5.11712005]\n",
      " [ 8.40898695]\n",
      " [ 4.83620935]]\n"
     ]
    }
   ],
   "source": [
    "# y değerini görelim\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19663736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X ile y arasındaki ilişkiyi görselleştirelim.\n",
    "\n",
    "plt.scatter(X, y)\n",
    "plt.xlabel(\"- X -\")\n",
    "plt.ylabel(\"- y -\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a1b9d",
   "metadata": {},
   "source": [
    "*Görüldüğü üzere X ile y arasındaki ilişki `lineer`'dir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863435a2",
   "metadata": {},
   "source": [
    "**X ile y arasındaki ilişkiyi bildiğimizi farz ederek yukarıdaki işlemleri gerçekleştirdik. Bu ilişkiye dair bilgi sahibi olmamızı sağlayan etken `intercept` ve `coefficient` değerlerininin tarafmızca belirlenmesidir. Böylece X ile y arasındaki ilişkiyi bildiğimiz senaryoyu gözlemleyerek regresyon modelini anımsamış olduk. Şimdi de gerçek X - y ilişkisinin fonksiyonunu yazalım.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0c0f8",
   "metadata": {},
   "source": [
    "### $$ y = w_0 + w_1X + \\epsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac52b4a5",
   "metadata": {},
   "source": [
    "Burada;\n",
    "\n",
    "* $w_0$ = $\\beta_0$\n",
    "* $w_1$ = $\\beta_1$\n",
    "* $\\epsilon$ = Error Rate\n",
    "\n",
    "* Burada $w_0$ ve $w_1$ değerleri W (weight) adlı bir matris içerisinde tutulup vektör olarak formatlanabilir.\n",
    "    * W vektörü: $W = [w_0 \\ w_1]$\n",
    "\n",
    "X-y arasındaki ilişkiyi bildiğimiz senaryoyu yeniden ele alalım. Intercept ve coefficient değerlerini regresyon denkleminde yerine koyarsak aşağıdaki sonucu elde ediyorduk:<br> \n",
    "### $$y = 4 + 3 * X + np.random.rand(100,1)$$<br>\n",
    "\n",
    "Buna göre;\n",
    "#### $$w_0 = 4$$\n",
    "#### $$w_1 = 3$$\n",
    "olur.<br>\n",
    "\n",
    "<br>Vektör kullanarak gösterecek olursak;\n",
    "### $$y = WX + \\epsilon$$\n",
    "şeklinde bir sonuç elde ederiz.<br>\n",
    "\n",
    "<br>Burada $W$ ile $X$ vektörlerinin $WX$ şeklinde gösterimi, W ile X'in *vektörel çarpımı*, `Dot Product (İç Çarpım)`'ıdır. Bu vektörel çarpım aslında; \n",
    "### $$\\hat y = w_0 + w_1*x_1 + w_2*x_2 + ... + w_n*x_n + \\epsilon$$\n",
    "ifadesi ile eşdeğerdir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe05e510",
   "metadata": {},
   "source": [
    "* Yukarıda, vektörler ile yeniden yazdığımız denklemi analitik olarak çözümleyebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af35e2",
   "metadata": {},
   "source": [
    "**NOT:** Makine öğrenmesinde vektörler; genellikle tek sütunlu 2-boyutlu diziler şeklinde, sütun vektörü olarak gösterilir. Eğer $W$ ve $X$ sütun vektörleri ise, tahmin $\\hat y = W^{T}X$ olur. Bu denklemde $W^{T}$, $W$'nin transpozudur, yani sütun vektörü yerine satır vektörüdür ve $W^{T}X$, $W^{T}$ ile $X$'in matris çarpımıdır. Elbette tahmin aynı tahmindir ancak tek bir fark söz konusudur: tahmin, artık skaler bir değer yerine tek hücreli bir matristir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2fef0d",
   "metadata": {},
   "source": [
    "### ANALİTİK ÇÖZÜM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c41897",
   "metadata": {},
   "source": [
    "$y = WX + \\epsilon$ denkleminin analitik çözümünü vektörler üzerinden gerçekleştirmeden önce Lineer Regresyon Yöntemi'ni kullanırken gerçekleştirdiğimiz analitik çözüm üzerinden gidelim. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ec0f2e",
   "metadata": {},
   "source": [
    "Least Squares Method (En Küçük Kareler Yöntemi), birbirine bağlı olarak değişen iki fiziksel büyüklük arasındaki ilişkiyi mümkün olduğunca gerçeğe uygun bir denklem olarak yazmak için kullanılan standart bir regresyon yöntemidir. Bir başka deyişle bu yöntem, ölçüm sonucu elde edilmiş veri noktalarına “mümkün olduğu kadar yakın” geçecek bir işlev eğrisi bulmaya yarar. Gauss-Markov Teoremi’nin en küçük kareler yöntemi, regresyon için optimal yöntemdir.\n",
    "\n",
    "Bir diğer ifadeyle; Least Squares Method, RSS değerini minimize ederek en iyi $w_0$ ve $w_1$ değerlerini tahmin eder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e82c18c",
   "metadata": {},
   "source": [
    "Herhangi bir $x_i$ için tahmin denklemi;\n",
    "### $$ \\hat y^{(i)} = \\hat w_0 + \\hat w_1 x^{(i)} $$\n",
    "\n",
    "Burada;\n",
    "* $x^{(i)}$: Veri setindeki $i^{inci}$ örneğin, etiketi(label) hariç tüm niteliklerinin değerlerini içeren bir vektördür.\n",
    "* $\\hat y^{(i)}$: Veri setindeki $i^{inci}$ örneğin etiketi, yani o örnek için istenen çıktı değeri.\n",
    "\n",
    "<br>Genel olarak:\n",
    "* **Değişkenler** için (x'in sütunları) alt index **($x_i$)** kullanılır.\n",
    "* **Veriler** için (satır) üst index **($x^{(i)}$)** kullanılır"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133756a1",
   "metadata": {},
   "source": [
    "Burada **X**'ler, yani girdi değerleri, bilindiğine göre, tahmin etmeye çalıştığımız değişkenler(katsayılar/coefficients), $w_0$ ve $w_1$'dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d87eea",
   "metadata": {},
   "source": [
    "**NOT**: Katsayılar(Coefficients) için aşağıdaki gösterimler kullanılabilir:\n",
    "* $w$\n",
    "* $\\theta$\n",
    "* $\\beta$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2b9c9",
   "metadata": {},
   "source": [
    "Bu noktadan itibaren gerçekleştirmek istediğimiz Tahmin için çalışmaya başlayalım."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be63746b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f83b79",
   "metadata": {},
   "source": [
    "Tahmin işlemini yukarıda bahsettiğimiz **Least Squares Method** ile gerçekleştiririz. Bunun yanında, Least Squares Method'un bir türü olan **Ordinary Least Squares Method**'u kullanacağız. \n",
    "\n",
    "<br>Ordinary Least Squares(OLS), Linear Regression modelinde bilinmeyen parametreleri tahmin etmek için kullanılan bir tür lineer Least Squares Method'dur. OLS, açıklayıcı değişkenler kümesinin doğrusal bir fonksiyonunun parametrelerini en küçük kareler ilkesine göre seçer: verilen veri kümesinde gözlemlenen bağımlı değişken (gözlemlenen değişkenin değerleri) ile bağımsız değişkenin doğrusal fonksiyonu tarafından tahmin edilenler arasındaki farkların karelerinin toplamını en aza indirir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c3cee2",
   "metadata": {},
   "source": [
    "**Hatırlatma**\n",
    "Herhangi bir **i** noktasındaki hata: $$e^{(i)} = \\hat y^{(i)} - y^{(i)}$$\n",
    "**<br>Herhangi Bir Noktadaki Hata Değeri = O Noktanın Tahmin Edilen Değeri - O Noktanın Gerçek Değeri** \n",
    "\n",
    "**e: Residual Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec9e521",
   "metadata": {},
   "source": [
    "**RSS: Residual Sum of Squares**\n",
    "$$RSS = e^2_1 + e^2_2 + e^2_3 +...+ e^2_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f72fde8",
   "metadata": {},
   "source": [
    "**Özetle, Least Square Method, RSS değerini minimize ederek en iyi $w_0$ ve $w_1$ değerlerini tahmin eder.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ae154",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b33e6",
   "metadata": {},
   "source": [
    "### MATEMATİKSEL GÖSTERİM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a35a43",
   "metadata": {},
   "source": [
    "### $$ \\hat w_1 = \\frac{\\sum_{i=1}^n (x^{(i)} - \\overline x)(y^{(i)} - \\overline y)}{\\sum_{i=1}^n (x^{(i)} - \\overline x)^2} $$\n",
    "\n",
    "### $$ \\hat w_0 = \\overline y - \\hat w_1 \\overline x $$\n",
    "\n",
    "Burada:\n",
    "\n",
    "### $$ \\overline y = \\frac{1}{n} \\sum_{i=1}^n y^{(i)} $$\n",
    "\n",
    "### $$ \\overline x = \\frac{1}{n} \\sum_{i=1}^n x^{(i)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22e406",
   "metadata": {},
   "source": [
    "Bu noktaya kadar elde ettiğimiz bilgilerden sonra şu ifadeyi ekleyelim: çoğu zaman Analitik Yöntem kullanarak çözüme ulaşmak mümkün olmaz çünkü üzerinde çalıştığımız veriler oldukça fazladır. X, W ve y'nin aslında birer `matris` olduğunu ve X matrisinin çoğu çalışmada yüksek boyutlara sahip olduğunu göz önünde bulundurursak vardığımız bu sonuç daha anlaşılır hale gelecektir. Bununla birlikte Analitik Yöntem kullanırken, W değerlerini bulmak için çok fazla Matrix Çarpımı yapılması gerekir ki bu, bilgisayarların GPU ve CPU donanımlarını ciddi oranda yoran bir işlemdir.\n",
    "\n",
    "Peki bu problemin üstesinden nasıl geleceğiz ya da nasıl daha etkili bir yöntem bulacağız. Cevap: YAKINSAYARAK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d2540c",
   "metadata": {},
   "source": [
    "**Problemin Tanımı**\n",
    "\n",
    "Toplam Hatayı minimize edecek $w_0$ ve $w_1$ değerlerini yani katsayıları bulmak.\n",
    "\n",
    "Toplam Hata, $w_0$ ve $w_1$ değişkenlerine bağlı bir Convex Fonksiyonudur. Bunun sebebi, Toplam Hatanın karesel değerlerin toplamı sonucunda bulunmasıdır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c56c3d",
   "metadata": {},
   "source": [
    "<img src=\"images/globalminimum.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1ea2c",
   "metadata": {},
   "source": [
    "### TERİMLER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b8e87",
   "metadata": {},
   "source": [
    "#### COST FUNCTION (MALİYET FONKSİYONU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5437f5",
   "metadata": {},
   "source": [
    "Lineer regresyonda **tahmin edilen y** değeri ile **gerçek y değeri** arasındaki hatayı minimuma indirebilmek için öyle **w değerleri** bulmalıyız ki Maliyet Fonksiyonu minimize edilebilsin. Maliyet Fonksiyonunun basit tanımı, gerçek y değerleri ile tahmin edilen y değerleri arasındaki fark şeklinde ifade edilebilir. Maliyet Fonksiyonu şu notasyonla gösterilir:\n",
    "### $$ J(w) = \\frac{1}{2n} \\sum_{i=1}^n (\\hat y^{(i)} - y^{(i)})^2 $$\n",
    "\n",
    "Cost Funtion aslında MSE(Mean Square Error)'nin özel bir formudur. Hatırlatmak için:\n",
    "### $$ MSE = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat y_i)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11df841e",
   "metadata": {},
   "source": [
    "#### GRADIENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402181a6",
   "metadata": {},
   "source": [
    "Cost Function'ın değişkenlere(W değerleri) göre değişim miktarı(Türevi) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf400b26",
   "metadata": {},
   "source": [
    "### $$ J(w) = \\frac{1}{2n} \\sum_{i=1}^n (\\hat w_0 + \\hat w_1x^{(i)} - y^{(i)})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2cfcf3",
   "metadata": {},
   "source": [
    "$w_0$'a göre kısmi türev:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b050a78",
   "metadata": {},
   "source": [
    "### $$ \\frac{\\partial J(w)}{\\partial w_0} = \\frac{1}{n} \\sum_{i=1}^n (\\hat w_0 + \\hat w_1x^{(i)} - y^{(i)}) $$\n",
    "\n",
    "### $$ \\frac{\\partial J(w)}{\\partial w_0} = \\frac{1}{n} \\sum_{i=1}^n (\\hat y^{(i)} - y^{(i)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41466097",
   "metadata": {},
   "source": [
    "$w_1$'e göre kısmi türev:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b3b17e",
   "metadata": {},
   "source": [
    "### $$ \\frac{\\partial J(w)}{\\partial w_1} = \\frac{1}{n} \\sum_{i=1}^n (\\hat w_0 + \\hat w_1x^{(i)} - y^{(i)}) x^{(i)} $$\n",
    "\n",
    "### $$ \\frac{\\partial J(w)}{\\partial w_1} = \\frac{1}{n} \\sum_{i=1}^n (\\hat y^{(i)} - y^{(i)}) x^{(i)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8373e16",
   "metadata": {},
   "source": [
    "Bu noktada, Cost Function(J)'ın **W** değerlerine göre nasıl değiştiğini, yani türevini, her bir $x^{(i)}$ ve $y^{(i)}$ noktasında bildiğimize göre bunu kullanabiliriz. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8db1d7",
   "metadata": {},
   "source": [
    "**Bu türeve *Gradient* adı verilir. Kısacası Gradient, J'nin W değerlerine göre nasıl değiştiğini bize söyleyen değişim vektörüdür.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe6d926",
   "metadata": {},
   "source": [
    "Gradient'in W vektörü üzerinden genel gösterimi:\n",
    "### $$ \\frac{\\partial J(W)}{\\partial W_j} = \\frac{1}{n} \\sum_{i=1}^n (\\hat y^{(i)} - y^{(i)}) X_j^{(i)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452be5b4",
   "metadata": {},
   "source": [
    "<img src=\"images/cost_function.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa3d883",
   "metadata": {},
   "source": [
    "### Gradient Descent Nasıl Çalışır?\n",
    "\n",
    "1. Önce bir başlangıç noktası seçilir ($w_0$ ve $w_1$)\n",
    "2. Bu noktası için Cost Function değeri **J(w)** hesaplanır\n",
    "3. Bu J(w) değeri üzerinden $w_0$ ve $w_1$ için **Gradient** hesaplanır\n",
    "4. Bu Gradient'in **negativ** değeri alınır (amacımız Cost Function'ı azaltmak çünkü)\n",
    "5. Bu negatif değer bir learning rate **$\\alpha$** ile çarpılır\n",
    "6. Bu çarpım sonucu ilgili $w$ değerinden çıkarlır\n",
    "7. Döngü tekrar 1. adımdan devam eder (Belirlenen iteration-döngü sayısında)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c80890",
   "metadata": {},
   "source": [
    "**Gradient Descent Akışı**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a29bf",
   "metadata": {},
   "source": [
    "Iterasyonlar üzerinen: $W$ yu update edeceğiz:\n",
    "\n",
    "**j**: iterasyon numarası"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221e6bb",
   "metadata": {},
   "source": [
    "### $$ W_j := W_j - \\alpha (\\frac{1}{n} \\sum_{i=1}^n (\\hat y^{(i)} - y^{(i)}) X_j^{(i)}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1af7d52",
   "metadata": {},
   "source": [
    "Burada **$\\alpha$ : learning rate**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
