{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1d8bd3",
   "metadata": {},
   "source": [
    "## f'yi Nasıl Tahmin Ederiz?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca552d7",
   "metadata": {},
   "source": [
    "Dersimiz boyunca, f'yi bulmak için birçok yöntem deneyeceğiz.\n",
    "\n",
    "Lineer Yöntemler, Non-Lineer Yöntemler, Clustering Yöntemleri deneyeceğimiz yöntemlere örnek olarak verilebilir.\n",
    "\n",
    "Bu yöntemler farklı olsalar da, hepsinde aşağıda belirtilen ortak varsayımlarımız olacak:\n",
    "\n",
    "* Her zaman n'in toplam gözlem sayısı (bağımsız veri sayısı) olduğunu kabul edeceğiz.\n",
    "* Bu gözlemlere 'training data' yani 'eğitme verisi' diyeceğiz.\n",
    "* Bu training data'yı kullanarak veri içindeki ilişkileri öğreneceğiz.\n",
    "* xij -> i. satır, j. sütun yani i numaralı gözlemin j numaralı değişkeni\n",
    "   * i = 1,2,3,...,n    \n",
    "   * j = 1,2,3...,p\n",
    "* yi -> i. data setinin sonucu yani output'u (label'i)\n",
    "* Amacımız training data üzerinde algoritmalar çalıştırıp bilmediğimiz f'yi tahminlemek\n",
    "* Bu arama işlemi iki temel yapıya ayrılır:\n",
    "    * Parametrik Metodlar\n",
    "    * Non-Parametrik Metodlar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f59004",
   "metadata": {},
   "source": [
    "***\n",
    "### **Parametrik Metodlar**\n",
    "\n",
    "* İki adımlı yaklaşımdır.\n",
    "\n",
    "**1- Önce f'nin şekli üzerine bir varsayımda bulunuruz (BIAS)**\n",
    "\n",
    "   Örneğin dağınık bir verimiz olduğunu ve bu veriyi parametre olarak gönderdiğimiz f fonksiyonunun `Lineer` olduğunu varsayabiliriz.\n",
    "   \n",
    "   $$f(X) = \\beta_o + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p $$\n",
    "   \n",
    "   Bu bir `Lineer Model`dir.\n",
    "   \n",
    "   Bu şekilde bir varsayımla artık f'yi tahminlemek için sadece $\\beta$ ları bulmak yeterlidir.\n",
    "   \n",
    "   Yani $p + 1$ adet $\\beta_0, \\beta_1, ... \\beta_p$ değişkenini.\n",
    "   \n",
    "   Dikkat ediniz, burada değişkenimiz X değildir, $\\beta$ 'lardır.\n",
    "   \n",
    "   Çünkü X'ler zaten her gözlem (satır) içinde verilmiştir.\n",
    "   \n",
    "   Y de bilmekteyiz yani sonucu.\n",
    "   \n",
    "   Bilmediğimiz tek şey $\\beta$ 'lardır.\n",
    "   \n",
    "   <img src='images/simple_linear_regression_model.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06036e",
   "metadata": {},
   "source": [
    "**2- Modeli seçtikten sonra training data üzerinden $\\beta$ 'ları bulacak bir prosedüre (algoritmaya) ihtiyaç duyarız.**\n",
    "\n",
    "Buna train dataya oturacak (fit edecek) bir model bulmak diyoruz.\n",
    "\n",
    "Modelimizin elimizdeki train datasına uyması için $\\beta$ katsayılarımız ne olacak? \n",
    "\n",
    "İşte bunu verecek bir prosedür gerekiyor bize.\n",
    "\n",
    "Bunun için kursumuz boyunca çeşitli yöntemler göreceğiz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db41e41",
   "metadata": {},
   "source": [
    "***\n",
    "## **Underfitting & Overfitting**\n",
    "\n",
    "Gördüğünüz gibi Parametrik Metodlar f'yi bulma meselesini aslında bir parametre tahmini meselesine indirgemiş olur.\n",
    "\n",
    "Dolayısı ile işimiz görece kolaylaşır.\n",
    "\n",
    "Ama bu durumda ortaya başka bir sorun çıkar. O da seçtiğimiz model'in geçekte var olan ama bizim bilmediğimiz modele ne kadar yakınsadığıdır. \n",
    "\n",
    "Eğer çok alakasız bir model seçimi yaptıysak o zaman bulduğumuz sonuçlar gerçekten uzak olacaktır.\n",
    "\n",
    "\n",
    "**Underfitting:** Başka bir deyişle seçtiğimiz model, gerçek hayattaki kompleksiteyi karşılayamamış demektir. Modelimiz çok basit kalmıştır.\n",
    "\n",
    "Bu soruna Makine Öğrenmesinde `Underfitting` denir.\n",
    "\n",
    "Lineer Modeller genelde basit oldukları için Underfitting'e düşme olasılığı yüksektir.\n",
    "\n",
    "**Overfitting:** Bir başka sorun da seçtiğimiz modelin çok fazla karmaşık olmasında çıkar. Eğer modelimiz gerçek hayattaki gizli fonksiyondan daha karmaşıksa o zaman da `Overfitting` var demektir.\n",
    "\n",
    "Yani modelimiz, veriyi çok fazla yakından izlemiş, yani ezberlemiştir. Eldeki veriyi çok iyi temsil etse de genelleşemez.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c44a2",
   "metadata": {},
   "source": [
    "<img src='images/overfitting_underfitting.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dacb91",
   "metadata": {},
   "source": [
    "***\n",
    "### **Non-Parametrik Metodlar**\n",
    "\n",
    "Parametrik Metodların aksine, Non-Parametrik Metodlar f'in şekli yani model üzerinde bir tahmin yapmazlar.\n",
    "\n",
    "Bunun yerine, direkt olarak veri üzerinden girdi-çıktı (input-output) arasındaki ilişkiyi anlamaya ve f'yi bu şekilde tahminlemeye çalışırlar.\n",
    "\n",
    "Dolayısı ile yanlış bir başlangıç yapma riskleri ortadan kalkar.\n",
    "\n",
    "Fakat Non-Parametrik Metodların da başka bir sorunu vardır. Çok ama çok veriye ihtiyaç duyarlar.\n",
    "\n",
    "Parametrik metodlarda olduğu gibi Non-Parametrik metodlar aradaki ilişkinin şeklini sabitlemedikleri için tüm olasılıklar masadadır ve bu olasılıkları elemek için büyük miktarda veriye ihtiyaç duyarlar. Ki bu da maliyet demektir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03516a4",
   "metadata": {},
   "source": [
    "**Parametrik vs. Non-Parametrik**\n",
    "\n",
    "Gördüğünüz gibi iki metodun da kendisine göre artıları ve eksileri var.\n",
    "\n",
    "Hangisini hangi durumda kullanacağımızı göreceğiz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
